{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "046ef8dc-9584-4ad3-976f-9f42c67324b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://a3e03c8a53e9:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark Introduction</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fcf5c71e920>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"Spark Introduction\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca8af50-7b40-4d22-99d5-d17c1b8f9cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emp Data & Schema\n",
    "# Dataset has taken from internet\n",
    "emp_data = [\n",
    "    [\"001\",\"101\",\"John Doe\",\"30\",\"Male\",\"50000\",\"2015-01-01\"],\n",
    "    [\"002\",\"101\",\"Jane Smith\",\"25\",\"Female\",\"45000\",\"2016-02-15\"],\n",
    "    [\"003\",\"102\",\"Bob Brown\",\"35\",\"Male\",\"55000\",\"2014-05-01\"],\n",
    "    [\"004\",\"102\",\"Alice Lee\",\"28\",\"Female\",\"48000\",\"2017-09-30\"],\n",
    "    [\"005\",\"103\",\"Jack Chan\",\"40\",\"Male\",\"60000\",\"2013-04-01\"],\n",
    "    [\"006\",\"103\",\"Jill Wong\",\"32\",\"Female\",\"52000\",\"2018-07-01\"],\n",
    "    [\"007\",\"101\",\"James Johnson\",\"42\",\"Male\",\"70000\",\"2012-03-15\"],\n",
    "    [\"008\",\"102\",\"Kate Kim\",\"29\",\"Female\",\"51000\",\"2019-10-01\"],\n",
    "    [\"009\",\"103\",\"Tom Tan\",\"33\",\"Male\",\"58000\",\"2016-06-01\"],\n",
    "    [\"010\",\"104\",\"Lisa Lee\",\"27\",\"Female\",\"47000\",\"2018-08-01\"],\n",
    "    [\"011\",\"104\",\"David Park\",\"38\",\"Male\",\"65000\",\"2015-11-01\"],\n",
    "    [\"012\",\"105\",\"Susan Chen\",\"31\",\"Female\",\"54000\",\"2017-02-15\"],\n",
    "    [\"013\",\"106\",\"Brian Kim\",\"45\",\"Male\",\"75000\",\"2011-07-01\"],\n",
    "    [\"014\",\"107\",\"Emily Lee\",\"26\",\"Female\",\"46000\",\"2019-01-01\"],\n",
    "    [\"015\",\"106\",\"Michael Lee\",\"37\",\"Male\",\"63000\",\"2014-09-30\"],\n",
    "    [\"016\",\"107\",\"Kelly Zhang\",\"30\",\"Female\",\"49000\",\"2018-04-01\"],\n",
    "    [\"017\",\"105\",\"George Wang\",\"34\",\"Male\",\"57000\",\"2016-03-15\"],\n",
    "    [\"018\",\"104\",\"Nancy Liu\",\"29\",\"Female\",\"50000\",\"2017-06-01\"],\n",
    "    [\"019\",\"103\",\"Steven Chen\",\"36\",\"Male\",\"62000\",\"2015-08-01\"],\n",
    "    [\"020\",\"102\",\"Grace Kim\",\"32\",\"Female\",\"53000\",\"2018-11-01\"]\n",
    "]\n",
    "\n",
    "emp_schema = \"employee_id string, department_id string, name string, age string, gender string, salary string, hire_date string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84d99031-3799-4bd2-8e96-0fcc9db50506",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df = spark.createDataFrame(schema=emp_schema, data=emp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b10bb5d3-f632-4f55-a160-21036b2e3b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('employee_id', StringType(), True), StructField('department_id', StringType(), True), StructField('name', StringType(), True), StructField('age', StringType(), True), StructField('gender', StringType(), True), StructField('salary', StringType(), True), StructField('hire_date', StringType(), True)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6e74229-03fc-414f-901a-fa77a4e7510f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = false)\n",
      " |-- age: integer (nullable = true)\n",
      "\n",
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "| John|  1|\n",
      "|Alice|  2|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType\n",
    "schema_string = \"name string,age int\"\n",
    "schema_spark = StructType([\n",
    "    StructField(\"name\",StringType(),False),\n",
    "    StructField(\"age\",IntegerType(),True)]\n",
    ")\n",
    "data = [[\"John\",1],[\"Alice\",2]]\n",
    "data_df=spark.createDataFrame(data,schema_spark)\n",
    "data_df.printSchema()\n",
    "data_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c839e061-2ea5-4745-96ac-47f3e2a7b654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+------+------------------+----------+---+\n",
      "|employee_id|department_id|salary|incremented_salary| hire_date|age|\n",
      "+-----------+-------------+------+------------------+----------+---+\n",
      "|        001|          101| 50000|           60000.0|2015-01-01| 30|\n",
      "|        002|          101| 45000|           55000.0|2016-02-15| 25|\n",
      "|        003|          102| 55000|           65000.0|2014-05-01| 35|\n",
      "|        004|          102| 48000|           58000.0|2017-09-30| 28|\n",
      "|        005|          103| 60000|           70000.0|2013-04-01| 40|\n",
      "|        006|          103| 52000|           62000.0|2018-07-01| 32|\n",
      "|        007|          101| 70000|           80000.0|2012-03-15| 42|\n",
      "|        008|          102| 51000|           61000.0|2019-10-01| 29|\n",
      "|        009|          103| 58000|           68000.0|2016-06-01| 33|\n",
      "|        010|          104| 47000|           57000.0|2018-08-01| 27|\n",
      "|        011|          104| 65000|           75000.0|2015-11-01| 38|\n",
      "|        012|          105| 54000|           64000.0|2017-02-15| 31|\n",
      "|        013|          106| 75000|           85000.0|2011-07-01| 45|\n",
      "|        014|          107| 46000|           56000.0|2019-01-01| 26|\n",
      "|        015|          106| 63000|           73000.0|2014-09-30| 37|\n",
      "|        016|          107| 49000|           59000.0|2018-04-01| 30|\n",
      "|        017|          105| 57000|           67000.0|2016-03-15| 34|\n",
      "|        018|          104| 50000|           60000.0|2017-06-01| 29|\n",
      "|        019|          103| 62000|           72000.0|2015-08-01| 36|\n",
      "|        020|          102| 53000|           63000.0|2018-11-01| 32|\n",
      "+-----------+-------------+------+------------------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Refering a column\n",
    "# Ways to select column col,expr,df.col,df['col'],'col'\n",
    "# expr also used like col but also it will evalutes expression\n",
    "from pyspark.sql.functions import col,expr\n",
    "emp_filetered = emp_df.select(col(\"employee_id\"),expr(\"department_id\"),emp_df.salary,expr(\"salary+10000\").alias(\"incremented_salary\"),\"hire_date\",emp_df[\"age\"])\n",
    "emp_filetered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d231809b-6154-43c0-89cc-3e9b452a6900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: string (nullable = true)\n",
      " |-- dept_id: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- incremented_salary: integer (nullable = true)\n",
      "\n",
      "+------+-------+------+------------------+\n",
      "|emp_id|dept_id|salary|incremented_salary|\n",
      "+------+-------+------+------------------+\n",
      "|   001|    101| 50000|             60000|\n",
      "|   002|    101| 45000|             55000|\n",
      "|   003|    102| 55000|             65000|\n",
      "|   004|    102| 48000|             58000|\n",
      "|   005|    103| 60000|             70000|\n",
      "|   006|    103| 52000|             62000|\n",
      "|   007|    101| 70000|             80000|\n",
      "|   008|    102| 51000|             61000|\n",
      "|   009|    103| 58000|             68000|\n",
      "|   010|    104| 47000|             57000|\n",
      "|   011|    104| 65000|             75000|\n",
      "|   012|    105| 54000|             64000|\n",
      "|   013|    106| 75000|             85000|\n",
      "|   014|    107| 46000|             56000|\n",
      "|   015|    106| 63000|             73000|\n",
      "|   016|    107| 49000|             59000|\n",
      "|   017|    105| 57000|             67000|\n",
      "|   018|    104| 50000|             60000|\n",
      "|   019|    103| 62000|             72000|\n",
      "|   020|    102| 53000|             63000|\n",
      "+------+-------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    emp_cast = emp_df.select(expr(\"employee_id as emp_id \"),expr(\"department_id as dept_id \"),emp_df.salary,expr(\"cast(salary+10000 as int)\").alias(\"incremented_salary\"))\n",
    "emp_cast.printSchema()\n",
    "emp_cast.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5cf65e85-a53f-4d74-a7f6-70270bcddc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: string (nullable = true)\n",
      " |-- dept_id: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- incremented_salary: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n",
      "+------+-------+------+------------------+---+\n",
      "|emp_id|dept_id|salary|incremented_salary|age|\n",
      "+------+-------+------+------------------+---+\n",
      "|   001|    101| 50000|             60000| 30|\n",
      "|   002|    101| 45000|             55000| 25|\n",
      "|   003|    102| 55000|             65000| 35|\n",
      "|   004|    102| 48000|             58000| 28|\n",
      "|   005|    103| 60000|             70000| 40|\n",
      "|   006|    103| 52000|             62000| 32|\n",
      "|   007|    101| 70000|             80000| 42|\n",
      "|   008|    102| 51000|             61000| 29|\n",
      "|   009|    103| 58000|             68000| 33|\n",
      "|   010|    104| 47000|             57000| 27|\n",
      "|   011|    104| 65000|             75000| 38|\n",
      "|   012|    105| 54000|             64000| 31|\n",
      "|   013|    106| 75000|             85000| 45|\n",
      "|   014|    107| 46000|             56000| 26|\n",
      "|   015|    106| 63000|             73000| 37|\n",
      "|   016|    107| 49000|             59000| 30|\n",
      "|   017|    105| 57000|             67000| 34|\n",
      "|   018|    104| 50000|             60000| 29|\n",
      "|   019|    103| 62000|             72000| 36|\n",
      "|   020|    102| 53000|             63000| 32|\n",
      "+------+-------+------+------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select + expr - selectExpr\n",
    "\n",
    "emp_cast_expr = emp_df.selectExpr(\"employee_id as emp_id \",\"department_id as dept_id \",\"salary\",\"cast(salary+10000 as int) as incremented_salary\",\"cast(age as int)\")\n",
    "emp_cast_expr.printSchema()\n",
    "emp_cast_expr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "068ad36a-0d6a-490e-8df7-f2bbd63779df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---+\n",
      "|emp_id|dept_id|salary|age|\n",
      "+------+-------+------+---+\n",
      "|   002|    101| 45000| 25|\n",
      "|   004|    102| 48000| 28|\n",
      "|   008|    102| 51000| 29|\n",
      "|   010|    104| 47000| 27|\n",
      "|   014|    107| 46000| 26|\n",
      "|   018|    104| 50000| 29|\n",
      "+------+-------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_cast_final = emp_cast_expr.select(\"emp_id\",\"dept_id\",\"salary\",\"age\").where(\"age<30\")\n",
    "emp_cast_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6649b46d-27a5-4003-829e-d2fd6f59d981",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_cast_final.repartition(1).write.format(\"csv\").save(\"data/output/2_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "53a768b9-dade-4d88-b756-6dbb1894b93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('name', StringType(), True), StructField('age', IntegerType(), True)])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How Spark convert schema_string into spark_schema\n",
    "\n",
    "from pyspark.sql.types import _parse_datatype_string\n",
    "schema_string = \"name string,age int\"\n",
    "\n",
    "spark_schema = _parse_datatype_string(schema_string)\n",
    "\n",
    "spark_schema"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
